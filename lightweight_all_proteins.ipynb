{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e36a90a-ea7c-403d-87f5-7413e9876b35",
   "metadata": {},
   "source": [
    "# NMDesc Protein Feature Parsing & Viewer\n",
    "\n",
    "This notebook parses **NIHMS1818854-supplement-2.xlsx** to produce a tidy feature table for proteins\n",
    "(e.g., Domains, PTMs, SLiMs, LCSs, NLSs/NESs, MORFs), and builds an interactive Plotly-based HTML\n",
    "viewer for quick inspection and variant annotation.\n",
    "\n",
    "**Inputs**\n",
    "- `NIHMS1818854-supplement-2.xlsx` (expected sheets: A, B, H)\n",
    "\n",
    "**Outputs**\n",
    "- `parsed_features.pkl`, `parsed_features.csv`\n",
    "- `docs/protein_data/*.json` (per-protein JSONs; **ALL proteins**)\n",
    "- `docs/protein_features_viewer_with_variants.html` (GitHub Pages-ready)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb48d7-3b79-4007-b59f-9277965145f8",
   "metadata": {},
   "source": [
    "## Environment & Dependencies\n",
    "\n",
    "This notebook targets Python 3 with the following packages:\n",
    "\n",
    "- `pandas`, `numpy`, `openpyxl` (for Excel), `plotly`\n",
    "\n",
    "Install (if needed):\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy openpyxl plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231efee5-253a-4d11-94b9-99181a3c77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config paths (edit as needed) ---\n",
    "EXCEL_PATH = \"NIHMS1818854-supplement-2.xlsx\"  # place the Excel next to the notebook\n",
    "\n",
    "# outputs (GitHub Pages convention: publish /docs)\n",
    "PICKLE_OUT = \"parsed_features.pkl\"\n",
    "CSV_OUT    = \"parsed_features.csv\"\n",
    "DATA_DIR   = \"docs/protein_data\"   # JSONs live under docs/\n",
    "OUT_HTML   = \"docs/protein_features_viewer_with_variants.html\"\n",
    "\n",
    "# Writer options\n",
    "MINIFY_JSON = True         # json minified to shrink size\n",
    "BUNDLE_BY_LETTER = False   # False = one file per protein; True = 26 files A..Z\n",
    "ALPHA_SUBFOLDERS = False   # If True, place per-protein files under docs/protein_data/A/, B/, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93046ea4-a3e2-4c4e-a76d-4faa59c82c01",
   "metadata": {},
   "source": [
    "## Parse Excel Sheets ‚Üí Tidy Feature Table\n",
    "\n",
    "- Normalizes column names (e.g., **LCSs** synonyms).\n",
    "- Parses range-like cells (`1-10, 14, 20-25`) and handles **MORFs** special format correctly.\n",
    "- Produces a long-format table with **Protein, Feature_Type, Start, End, Source_Column, seq_len**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1acead3f-df09-4294-b0d6-78fddb803348",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved parsed_features.pkl and parsed_features.csv\n",
      "Rows: 1,012,180 | Proteins: 20,145\n",
      "\n",
      "By source column:\n",
      "Source_Column\n",
      "PTMs                373588\n",
      "Protein Features    373429\n",
      "LCSs                159533\n",
      "Domains              57956\n",
      "NLSs/NESs            45822\n",
      "SLiMs                 1771\n",
      "MORFs                   81\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re, math, json, os\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Helper: normalize any LCSs-like column name to 'LCSs'import re, os, math, json\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "os.makedirs(\"docs\", exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# normalize any LCSs-like column name to 'LCSs'\n",
    "def normalize_lcs_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    candidates = [\n",
    "        \"LCSs\", \"LCS\", \"Low complexity\", \"Low-complexity\",\n",
    "        \"Low complexity regions\", \"Low-complexity regions\",\n",
    "        \"Low_complexity\", \"Low complexity (LCSs)\"\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            if c != \"LCSs\":\n",
    "                df = df.rename(columns={c: \"LCSs\"})\n",
    "            break\n",
    "    if \"LCSs\" not in df.columns:\n",
    "        df[\"LCSs\"] = np.nan\n",
    "    return df\n",
    "\n",
    "# --- Load sheets ---\n",
    "sheetA = pd.read_excel(EXCEL_PATH, sheet_name=\"A\")\n",
    "sheetA = sheetA.rename(columns={\n",
    "    \"UniProt ID\":\"Uniprot ID\", \"UniProtID\":\"Uniprot ID\",\n",
    "    \"seq\":\"Sequence\", \"sequence\":\"Sequence\"\n",
    "})\n",
    "sheetA[\"Protein\"] = sheetA[\"Protein\"].astype(str).str.strip()\n",
    "sheetA[\"Protein_norm\"] = sheetA[\"Protein\"].str.upper()\n",
    "sheetA[\"seq_len\"] = sheetA[\"Sequence\"].astype(str).str.len()\n",
    "seq_len_map = sheetA.groupby(\"Protein_norm\")[\"seq_len\"].max().to_dict()\n",
    "\n",
    "# B and H contain features (G duplicates LCSs in some versions)\n",
    "sheet_b = pd.read_excel(EXCEL_PATH, sheet_name=\"B\"); sheet_b[\"Sheet\"] = \"B\"\n",
    "sheet_h = pd.read_excel(EXCEL_PATH, sheet_name=\"H\"); sheet_h[\"Sheet\"] = \"H\"\n",
    "sheet_b = normalize_lcs_columns(sheet_b)\n",
    "sheet_h = normalize_lcs_columns(sheet_h)\n",
    "\n",
    "raw = pd.concat([sheet_b, sheet_h], ignore_index=True)\n",
    "\n",
    "# columns we use\n",
    "cols = [\"Protein\",\"Protein Features\",\"Domains\",\"SLiMs\",\"MORFs\",\"PTMs\",\"NLSs/NESs\",\"LCSs\",\"Sheet\"]\n",
    "cols = [c for c in cols if c in raw.columns]\n",
    "raw = raw[cols].copy()\n",
    "raw[\"Protein\"] = raw[\"Protein\"].astype(str).str.strip()\n",
    "raw[\"Protein_norm\"] = raw[\"Protein\"].str.upper()\n",
    "\n",
    "# --- Parse cells ---\n",
    "block_re = re.compile(r'([^(),]+?)\\s*\\(([^)]*)\\)')  # e.g. \"Feature (1-10, 14, 20-25)\"\n",
    "\n",
    "def parse_cell(cell_text, column_name=None):\n",
    "    out = []\n",
    "    if pd.isna(cell_text): \n",
    "        return out\n",
    "    s = str(cell_text).strip()\n",
    "    if not s: \n",
    "        return out\n",
    "    \n",
    "    # MORFs often appear as just ranges \"1-10, 14-20\" without a feature label\n",
    "    if column_name == \"MORFs\":\n",
    "        feat = \"MORF\"\n",
    "        for tok in s.split(\",\"):\n",
    "            tok = tok.strip()\n",
    "            if not tok:\n",
    "                continue\n",
    "            if \"-\" in tok:\n",
    "                a, b = tok.split(\"-\", 1)\n",
    "                try:\n",
    "                    st, en = int(a.strip()), int(b.strip())\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    st = en = int(tok)\n",
    "                except:\n",
    "                    continue\n",
    "            if st > 0 and en > 0:\n",
    "                out.append((feat, st, en))\n",
    "        return out\n",
    "    \n",
    "    # standard \"FeatureName (1-10, 14, 20-25)\" blocks\n",
    "    for name, inner in block_re.findall(s):\n",
    "        feat = name.strip().strip(\",\")\n",
    "        for tok in inner.split(\",\"):\n",
    "            tok = tok.strip()\n",
    "            if not tok:\n",
    "                continue\n",
    "            if \"-\" in tok:\n",
    "                a, b = tok.split(\"-\", 1)\n",
    "                try:\n",
    "                    st, en = int(a.strip()), int(b.strip())\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    st = en = int(tok)\n",
    "                except:\n",
    "                    continue\n",
    "            if st > 0 and en > 0:\n",
    "                out.append((feat, st, en))\n",
    "    return out\n",
    "\n",
    "tidy_rows = []\n",
    "for _, r in raw.iterrows():\n",
    "    prot = r[\"Protein\"]; pn = r[\"Protein_norm\"]\n",
    "    for col in [\"Protein Features\",\"Domains\",\"SLiMs\",\"MORFs\",\"PTMs\",\"NLSs/NESs\",\"LCSs\"]:\n",
    "        if col not in raw.columns:\n",
    "            continue\n",
    "        for ft, st, en in parse_cell(r.get(col, None), column_name=col):\n",
    "            tidy_rows.append([prot, pn, ft, st, en, col])\n",
    "\n",
    "parsed = pd.DataFrame(\n",
    "    tidy_rows,\n",
    "    columns=[\"Protein\",\"Protein_norm\",\"Feature_Type\",\"Start\",\"End\",\"Source_Column\"]\n",
    ")\n",
    "\n",
    "# attach sequence length\n",
    "parsed[\"seq_len\"] = parsed[\"Protein_norm\"].map(seq_len_map)\n",
    "\n",
    "# cleanups\n",
    "parsed = parsed.dropna(subset=[\"Start\",\"End\"])\n",
    "parsed[\"Start\"] = pd.to_numeric(parsed[\"Start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "parsed[\"End\"]   = pd.to_numeric(parsed[\"End\"], errors=\"coerce\").astype(\"Int64\")\n",
    "parsed = parsed.dropna(subset=[\"Start\",\"End\"]).astype({\"Start\":\"int\",\"End\":\"int\"})\n",
    "parsed = parsed[parsed[\"End\"] >= parsed[\"Start\"]]\n",
    "parsed = parsed.drop_duplicates(\n",
    "    subset=[\"Protein_norm\",\"Feature_Type\",\"Start\",\"End\",\"Source_Column\"]\n",
    ")\n",
    "\n",
    "# save tidy outputs\n",
    "parsed.to_pickle(PICKLE_OUT)\n",
    "parsed.to_csv(CSV_OUT, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved {PICKLE_OUT} and {CSV_OUT}\")\n",
    "print(f\"Rows: {len(parsed):,} | Proteins: {parsed['Protein'].nunique():,}\")\n",
    "print(\"\\nBy source column:\")\n",
    "print(parsed[\"Source_Column\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e41be-452e-4db6-8968-6656015a42fa",
   "metadata": {},
   "source": [
    "## Quick Preview of Parsed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84eee624-a421-4adf-adb9-cde9964f0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1012180\n",
      "Proteins: 20145\n",
      "Source_Column\n",
      "PTMs                373588\n",
      "Protein Features    373429\n",
      "LCSs                159533\n",
      "Domains              57956\n",
      "NLSs/NESs            45822\n",
      "SLiMs                 1771\n",
      "MORFs                   81\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein</th>\n",
       "      <th>Protein_norm</th>\n",
       "      <th>Feature_Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Source_Column</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Cross-link</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>137</td>\n",
       "      <td>161</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>167</td>\n",
       "      <td>182</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>187</td>\n",
       "      <td>203</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>204</td>\n",
       "      <td>207</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1433B</td>\n",
       "      <td>1433B</td>\n",
       "      <td>Helix</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>Protein Features</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein Protein_norm Feature_Type  Start  End     Source_Column  seq_len\n",
       "0   1433B        1433B   Cross-link     51   51  Protein Features      246\n",
       "1   1433B        1433B        Helix    114  134  Protein Features      246\n",
       "2   1433B        1433B        Helix    137  161  Protein Features      246\n",
       "3   1433B        1433B        Helix    167  182  Protein Features      246\n",
       "4   1433B        1433B        Helix    187  203  Protein Features      246\n",
       "5   1433B        1433B        Helix    204  207  Protein Features      246\n",
       "6   1433B        1433B        Helix     21   32  Protein Features      246\n",
       "7   1433B        1433B        Helix    213  231  Protein Features      246\n",
       "8   1433B        1433B        Helix     40   70  Protein Features      246\n",
       "9   1433B        1433B        Helix      5   17  Protein Features      246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = pd.read_pickle(PICKLE_OUT)\n",
    "print(\"Rows:\", len(parsed))\n",
    "print(\"Proteins:\", parsed[\"Protein\"].nunique())\n",
    "print(parsed[\"Source_Column\"].value_counts())\n",
    "parsed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16a10a-ef31-4316-8651-11f403455f26",
   "metadata": {},
   "source": [
    "## Build Interactive Viewer (Plotly)\n",
    "\n",
    "- Creates `protein_data/` with per-protein JSONs.\n",
    "- Writes a self-contained viewer to `docs/protein_features_view_with_variants.html` suitable for GitHub Pages.\n",
    "- Use the select box to choose a protein; you can add variant markers by editing the little snippet inside the script if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd430f3-2ac2-4089-b8f2-30425e97c333",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Wrote 500/20145 proteins\n",
      "  Wrote 1000/20145 proteins\n",
      "  Wrote 1500/20145 proteins\n",
      "  Wrote 2000/20145 proteins\n",
      "  Wrote 2500/20145 proteins\n",
      "  Wrote 3000/20145 proteins\n",
      "  Wrote 3500/20145 proteins\n",
      "  Wrote 4000/20145 proteins\n",
      "  Wrote 4500/20145 proteins\n",
      "  Wrote 5000/20145 proteins\n",
      "  Wrote 5500/20145 proteins\n",
      "  Wrote 6000/20145 proteins\n",
      "  Wrote 6500/20145 proteins\n",
      "  Wrote 7000/20145 proteins\n",
      "  Wrote 7500/20145 proteins\n",
      "  Wrote 8000/20145 proteins\n",
      "  Wrote 8500/20145 proteins\n",
      "  Wrote 9000/20145 proteins\n",
      "  Wrote 9500/20145 proteins\n",
      "  Wrote 10000/20145 proteins\n",
      "  Wrote 10500/20145 proteins\n",
      "  Wrote 11000/20145 proteins\n",
      "  Wrote 11500/20145 proteins\n",
      "  Wrote 12000/20145 proteins\n",
      "  Wrote 12500/20145 proteins\n",
      "  Wrote 13000/20145 proteins\n",
      "  Wrote 13500/20145 proteins\n",
      "  Wrote 14000/20145 proteins\n",
      "  Wrote 14500/20145 proteins\n",
      "  Wrote 15000/20145 proteins\n",
      "  Wrote 15500/20145 proteins\n",
      "  Wrote 16000/20145 proteins\n",
      "  Wrote 16500/20145 proteins\n",
      "  Wrote 17000/20145 proteins\n",
      "  Wrote 17500/20145 proteins\n",
      "  Wrote 18000/20145 proteins\n",
      "  Wrote 18500/20145 proteins\n",
      "  Wrote 19000/20145 proteins\n",
      "  Wrote 19500/20145 proteins\n",
      "  Wrote 20000/20145 proteins\n",
      "‚úÖ Wrote viewer: docs/protein_features_viewer_with_variants.html\n",
      "Proteins written: 20145\n",
      "JSON location: docs/protein_data (bundle_by_letter=False, alpha_subfolders=False)\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# normalize Source_Column drift for rendering\n",
    "parsed_for_view = parsed.copy()\n",
    "parsed_for_view[\"Source_Column\"] = (\n",
    "    parsed_for_view[\"Source_Column\"].astype(str).str.strip()\n",
    "    .replace({\n",
    "        \"LCS\": \"LCSs\",\n",
    "        \"Low complexity\": \"LCSs\",\n",
    "        \"LOW COMPLEXITY\": \"LCSs\",\n",
    "        \"Low-complexity\": \"LCSs\",\n",
    "    })\n",
    ")\n",
    "\n",
    "track_order = [\"PTMs\", \"Protein Features\", \"SLiMs\", \"LCSs\", \"NLSs/NESs\", \"MORFs\"]\n",
    "BAND_FILL = \"rgba(0,0,0,0.03)\"\n",
    "COLOR_RANGE_FILL_DEFAULT = \"rgba(66,135,245,0.35)\"\n",
    "COLOR_RANGE_LINE_DEFAULT = \"rgba(0,0,0,0.35)\"\n",
    "COLOR_POINT_DEFAULT      = \"#9467bd\"\n",
    "TRACK_RANGE_FILL = {\n",
    "    \"Domains\":          \"rgba(66,135,245,0.35)\",\n",
    "    \"PTMs\":             \"rgba(148,103,189,0.30)\",\n",
    "    \"Protein Features\": \"rgba(70,70,70,0.08)\",\n",
    "    \"SLiMs\":            \"rgba(255,159,64,0.28)\",\n",
    "    \"LCSs\":             \"rgba(50,205,50,0.45)\",\n",
    "    \"NLSs/NESs\":        \"rgba(23,162,184,0.28)\",\n",
    "    \"MORFs\":            \"rgba(220,53,69,0.22)\",\n",
    "}\n",
    "TRACK_RANGE_LINE = {\"LCSs\":  {\"color\": \"rgba(0,0,0,0.60)\", \"width\": 1.6}}\n",
    "TRACK_POINT_COLOR = {\n",
    "    \"PTMs\":             \"#8a63c2\",\n",
    "    \"Protein Features\": \"#6c757d\",\n",
    "    \"SLiMs\":            \"#e67e22\",\n",
    "    \"LCSs\":             \"#1e7e34\",\n",
    "    \"NLSs/NESs\":        \"#17a2b8\",\n",
    "    \"MORFs\":            \"#dc3545\",\n",
    "}\n",
    "\n",
    "VARIANT_COLOR = \"#ff0000\"\n",
    "y_backbone = 0.5\n",
    "y_spacing  = 1.45\n",
    "y_positions = {name: (len(track_order)-i)*y_spacing for i, name in enumerate(track_order)}\n",
    "\n",
    "PLOTLY_CONFIG = dict(\n",
    "    toImageButtonOptions=dict(format=\"png\", filename=\"protein_features\", scale=2),\n",
    "    displaylogo=False\n",
    ")\n",
    "\n",
    "proteins_all = sorted(parsed_for_view[\"Protein\"].unique())\n",
    "protein_map = {}  # {original_name: safe_filename}\n",
    "\n",
    "def _range_fill_for(col: str) -> str:\n",
    "    return TRACK_RANGE_FILL.get(col, COLOR_RANGE_FILL_DEFAULT)\n",
    "\n",
    "def _range_line_for(col: str) -> dict:\n",
    "    base = {\"color\": COLOR_RANGE_LINE_DEFAULT, \"width\": 1}\n",
    "    base.update(TRACK_RANGE_LINE.get(col, {}))\n",
    "    return base\n",
    "\n",
    "def _point_color_for(col: str) -> str:\n",
    "    return TRACK_POINT_COLOR.get(col, COLOR_POINT_DEFAULT)\n",
    "\n",
    "def safe_length(sub):\n",
    "    seq = sub[\"seq_len\"].dropna()\n",
    "    if not seq.empty:\n",
    "        try:\n",
    "            L = int(seq.iloc[0])\n",
    "            if L > 0:\n",
    "                return L\n",
    "        except:\n",
    "            pass\n",
    "    max_feat = int(pd.to_numeric(sub[\"End\"], errors=\"coerce\").max()) if not sub.empty else 0\n",
    "    return int(math.ceil(max_feat * 1.03 + 3))\n",
    "\n",
    "def build_payload_for_protein(prot, include_single_sites=True):\n",
    "    sub = parsed_for_view[parsed_for_view[\"Protein\"]==prot].copy()\n",
    "    if sub.empty:\n",
    "        L = 100\n",
    "        return dict(data=[], shapes=[], annotations=[], xr=[0,L], yr=[-0.6,5], tv=[], tt=[], title=f\"{prot}\", protein_length=L)\n",
    "    L = safe_length(sub)\n",
    "    shapes, ann, traces = [], [], []\n",
    "    # backbone\n",
    "    shapes.append(dict(type=\"rect\", x0=0, x1=L, y0=y_backbone-0.2, y1=y_backbone+0.2, line=dict(width=0), fillcolor=\"#9ea0a3\"))\n",
    "    ann.append(dict(x=L, y=y_backbone+0.35, text=f\"{L} aa\", showarrow=False))\n",
    "\n",
    "    # domains on backbone\n",
    "    dom = sub[sub[\"Source_Column\"]==\"Domains\"].copy()\n",
    "    if not dom.empty:\n",
    "        dom[\"Start\"] = pd.to_numeric(dom[\"Start\"], errors=\"coerce\")\n",
    "        dom[\"End\"]   = pd.to_numeric(dom[\"End\"],   errors=\"coerce\")\n",
    "    for _, r in dom.iterrows():\n",
    "        st, en = float(r[\"Start\"]), float(r[\"End\"])\n",
    "        feat = str(r[\"Feature_Type\"]) if pd.notna(r[\"Feature_Type\"]) else \"\"\n",
    "        label = feat if len(feat)<=20 else feat[:17]+\"...\"\n",
    "        shapes.append(dict(type=\"rect\", x0=st, x1=en, y0=y_backbone-0.28, y1=y_backbone+0.28,\n",
    "                           line=dict(color=COLOR_RANGE_LINE_DEFAULT, width=1),\n",
    "                           fillcolor=TRACK_RANGE_FILL.get(\"Domains\", COLOR_RANGE_FILL_DEFAULT)))\n",
    "        if en-st >= 15:\n",
    "            ann.append(dict(x=(st+en)/2, y=y_backbone, text=label, showarrow=False,\n",
    "                            font=dict(size=10, color=\"black\"), xanchor=\"center\", yanchor=\"middle\", align=\"center\"))\n",
    "        traces.append(go.Scatter(x=[(st+en)/2], y=[y_backbone], mode=\"markers\", marker=dict(size=8, opacity=0),\n",
    "                                 showlegend=False, hoverinfo=\"text\", hovertext=f\"Domain: {feat} ({int(st)}‚Äì{int(en)})\"))\n",
    "\n",
    "    # other tracks\n",
    "    for col in track_order:\n",
    "        y = y_positions[col]\n",
    "        shapes.append(dict(type=\"rect\", x0=0, x1=L, y0=y-0.28, y1=y+0.28, line=dict(width=0), fillcolor=BAND_FILL))\n",
    "        chunk = sub[sub[\"Source_Column\"]==col].copy()\n",
    "        if chunk.empty: \n",
    "            continue\n",
    "        chunk[\"Start\"] = pd.to_numeric(chunk[\"Start\"], errors=\"coerce\")\n",
    "        chunk[\"End\"]   = pd.to_numeric(chunk[\"End\"],   errors=\"coerce\")\n",
    "\n",
    "        rng = chunk[chunk[\"End\"].fillna(chunk[\"Start\"]) > chunk[\"Start\"]]\n",
    "        for _, r in rng.iterrows():\n",
    "            st = float(r[\"Start\"]); en = float(r[\"End\"])\n",
    "            ftype = (r.get(\"Feature_Type\") if pd.notna(r.get(\"Feature_Type\")) else \"\") or \"\"\n",
    "            shapes.append(dict(type=\"rect\", x0=st, x1=en, y0=y-0.28, y1=y+0.28,\n",
    "                               line=_range_line_for(col), fillcolor=_range_fill_for(col)))\n",
    "            traces.append(go.Scatter(x=[(st+en)/2], y=[y], mode=\"markers\",\n",
    "                                     marker=dict(size=8, opacity=0), showlegend=False,\n",
    "                                     hoverinfo=\"text\", hovertext=f\"{col}: {ftype} ({int(st)}‚Äì{int(en)})\"))\n",
    "\n",
    "        pts = chunk[chunk[\"End\"].fillna(chunk[\"Start\"]) == chunk[\"Start\"]]\n",
    "        for _, r in pts.iterrows():\n",
    "            x = float(r[\"Start\"])\n",
    "            ftype = (r.get(\"Feature_Type\") if pd.notna(r.get(\"Feature_Type\")) else \"\") or \"\"\n",
    "            shapes.append(dict(type=\"line\", x0=x, x1=x, y0=y-0.22, y1=y+0.22, line=dict(color=_point_color_for(col), width=2)))\n",
    "            traces.append(go.Scatter(x=[x], y=[y], mode=\"markers\",\n",
    "                                     marker=dict(size=8, color=_point_color_for(col), opacity=0.0),\n",
    "                                     hoverinfo=\"text\", hovertext=f\"{col}: {ftype} ({int(x)})\", showlegend=False))\n",
    "\n",
    "    tickvals = [y_positions[n] for n in track_order] + [y_backbone]\n",
    "    ticktext = track_order[:] + [\"backbone\"]\n",
    "    y_range = [-0.6, max(tickvals)+1.0]\n",
    "    title = f\"{prot}\"\n",
    "    return dict(data=[t.to_plotly_json() for t in traces], shapes=shapes, annotations=ann,\n",
    "                xr=[0, L], yr=y_range, tv=tickvals, tt=ticktext, title=title, protein_length=L)\n",
    "\n",
    "# ---------- Write ALL payloads ----------\n",
    "from collections import defaultdict\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    return s.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "if BUNDLE_BY_LETTER:\n",
    "    # 26 bundle files A..Z\n",
    "    bundles = defaultdict(dict)  # {\"A\": {prot: payload, ...}, ...}\n",
    "    for i, prot in enumerate(proteins_all, 1):\n",
    "        payload = {\n",
    "            \"withSingles\": build_payload_for_protein(prot, include_single_sites=True),\n",
    "            \"noSingles\":   build_payload_for_protein(prot, include_single_sites=False),\n",
    "        }\n",
    "        bundles[safe_name(prot)[0].upper()][prot] = payload\n",
    "        if i % 500 == 0:\n",
    "            print(f\"  Bundled {i}/{len(proteins_all)}...\")\n",
    "    for letter, obj in bundles.items():\n",
    "        out = os.path.join(DATA_DIR, f\"{letter}.json\")\n",
    "        with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "            if MINIFY_JSON:\n",
    "                json.dump(obj, f, separators=(\",\", \":\"))\n",
    "            else:\n",
    "                json.dump(obj, f, indent=2)\n",
    "        print(f\"Wrote {out} with {len(obj)} proteins\")\n",
    "else:\n",
    "    # per-protein JSON, optional A‚ÄìZ subfolders\n",
    "    if ALPHA_SUBFOLDERS:\n",
    "        for L in [chr(c) for c in range(ord(\"A\"), ord(\"Z\")+1)]:\n",
    "            os.makedirs(os.path.join(DATA_DIR, L), exist_ok=True)\n",
    "\n",
    "    for i, prot in enumerate(proteins_all, 1):\n",
    "        safe = safe_name(prot)\n",
    "        protein_map[prot] = safe\n",
    "        subdir = os.path.join(DATA_DIR, safe[0].upper()) if ALPHA_SUBFOLDERS else DATA_DIR\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "        out = os.path.join(subdir, f\"{safe}.json\")\n",
    "        payload = {\n",
    "            \"withSingles\": build_payload_for_protein(prot, include_single_sites=True),\n",
    "            \"noSingles\":   build_payload_for_protein(prot, include_single_sites=False),\n",
    "        }\n",
    "        with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "            if MINIFY_JSON:\n",
    "                json.dump(payload, f, separators=(\",\", \":\"))\n",
    "            else:\n",
    "                json.dump(payload, f, indent=2)\n",
    "        if i % 500 == 0:\n",
    "            print(f\"  Wrote {i}/{len(proteins_all)} proteins\")\n",
    "\n",
    "# ---------- Build the HTML shell ----------\n",
    "seed = {\"data\": [], \"shapes\": [], \"annotations\": [dict(x=0.5, y=0.5, xref=\"paper\", yref=\"paper\",\n",
    "         text=\"Select a protein to begin...\", showarrow=False, font=dict(size=16, color=\"#666\"))],\n",
    "        \"xr\": [0, 100], \"yr\": [-0.6, 5], \"tv\": [], \"tt\": [], \"title\": \"Protein Features Viewer with Variants\"}\n",
    "\n",
    "fig = go.Figure(seed[\"data\"])\n",
    "fig.update_layout(title=seed[\"title\"], shapes=seed[\"shapes\"], annotations=seed[\"annotations\"],\n",
    "                  margin=dict(l=90, r=30, t=110, b=60), showlegend=True, paper_bgcolor=\"white\")\n",
    "fig.update_xaxes(range=seed[\"xr\"], title=\"Amino acid position\", showgrid=False, zeroline=False)\n",
    "fig.update_yaxes(range=seed[\"yr\"], tickvals=seed[\"tv\"], ticktext=seed[\"tt\"], showgrid=False)\n",
    "html_core = pio.to_html(fig, include_plotlyjs=\"cdn\", full_html=True, config=PLOTLY_CONFIG)\n",
    "\n",
    "# controls/loader (supports both per-protein JSON and A‚ÄìZ bundles)\n",
    "if BUNDLE_BY_LETTER:\n",
    "    controls_html = f\"\"\"\n",
    "<script>\n",
    "function initViewer() {{\n",
    "  if (typeof Plotly === 'undefined') {{ setTimeout(initViewer, 100); return; }}\n",
    "  const PROTEINS = {json.dumps(proteins_all)};\n",
    "  const DATA_DIR = \"protein_data\";\n",
    "  const BUNDLE_CACHE = {{}};\n",
    "\n",
    "  const gd = document.querySelector('.js-plotly-plot');\n",
    "  const sel = document.createElement('select');\n",
    "  sel.style.margin = '8px';\n",
    "  PROTEINS.forEach(p=>{{ const o=document.createElement('option'); o.value=p; o.textContent=p; sel.appendChild(o); }});\n",
    "  gd.parentNode.insertBefore(sel, gd);\n",
    "\n",
    "  async function loadP(p) {{\n",
    "    const letter = (p[0] || \"X\").toUpperCase();\n",
    "    if (!BUNDLE_CACHE[letter]) {{\n",
    "      const resp = await fetch(`${{DATA_DIR}}/${{letter}}.json`);\n",
    "      BUNDLE_CACHE[letter] = await resp.json();\n",
    "    }}\n",
    "    return BUNDLE_CACHE[letter][p];\n",
    "  }}\n",
    "\n",
    "  function varShapes(vs, yTop) {{\n",
    "    const VARIANT_COLOR = \"#ff0000\", y_backbone = 0.5;\n",
    "    const shapes = [], traces = [];\n",
    "    vs.forEach(v => {{\n",
    "      const x = v.position;\n",
    "      shapes.push({{type:'line', x0:x, x1:x, y0:-0.5, y1:yTop, line:{{color:VARIANT_COLOR, width:2}} }});\n",
    "      traces.push({{x:[x], y:[y_backbone], mode:'markers', marker:{{symbol:'diamond', size:12, color:VARIANT_COLOR, line:{{color:'white', width:1}}}}, hoverinfo:'text', hovertext:`Variant ${{v.display}}` }});\n",
    "    }});\n",
    "    return {{shapes, traces}};\n",
    "  }}\n",
    "\n",
    "  let currentVariants = [];\n",
    "  async function apply(p) {{\n",
    "    const state = (await loadP(p))['noSingles'];\n",
    "    const extra = varShapes(currentVariants, state.yr[1]);\n",
    "    Plotly.react(gd, [...state.data, ...extra.traces], {{\n",
    "      ...gd.layout, title: {{text: state.title}},\n",
    "      shapes: [...state.shapes, ...extra.shapes], annotations: state.annotations,\n",
    "      xaxis: {{...gd.layout.xaxis, range: state.xr, title: {{text:'Amino acid position'}}, showgrid:false, zeroline:false}},\n",
    "      yaxis: {{...gd.layout.yaxis, range: state.yr, tickvals: state.tv, ticktext: state.tt, showgrid:false}}\n",
    "    }});\n",
    "  }}\n",
    "\n",
    "  sel.addEventListener('change', ()=>apply(sel.value));\n",
    "  sel.value = PROTEINS[0]; apply(sel.value);\n",
    "}}\n",
    "document.readyState === 'loading' ? document.addEventListener('DOMContentLoaded', initViewer) : initViewer();\n",
    "</script>\n",
    "\"\"\"\n",
    "else:\n",
    "    # per protein; if ALPHA_SUBFOLDERS=True, we fetch from protein_data/<LETTER>/<file>.json\n",
    "    fetch_expr = \"\"\"`${DATA_DIR}/${PROTEIN_MAP[p][0].toUpperCase()}/${PROTEIN_MAP[p]}.json`\"\"\" if ALPHA_SUBFOLDERS else \"\"\"`${DATA_DIR}/${PROTEIN_MAP[p]}.json`\"\"\"\n",
    "    controls_html = f\"\"\"\n",
    "<script>\n",
    "function initViewer() {{\n",
    "  if (typeof Plotly === 'undefined') {{ setTimeout(initViewer, 100); return; }}\n",
    "  const PROTEINS = {json.dumps(proteins_all)};\n",
    "  const PROTEIN_MAP = {json.dumps({p: p.replace('/','_').replace('\\\\\\\\','_').replace(':','_') for p in proteins_all})};\n",
    "  const DATA_DIR = \"protein_data\";\n",
    "  const cache = {{}};\n",
    "\n",
    "  const gd = document.querySelector('.js-plotly-plot');\n",
    "  const sel = document.createElement('select');\n",
    "  sel.style.margin = '8px';\n",
    "  PROTEINS.forEach(p=>{{ const o=document.createElement('option'); o.value=p; o.textContent=p; sel.appendChild(o); }});\n",
    "  gd.parentNode.insertBefore(sel, gd);\n",
    "\n",
    "  async function loadP(p) {{\n",
    "    if (cache[p]) return cache[p];\n",
    "    const resp = await fetch({fetch_expr});\n",
    "    const data = await resp.json(); cache[p]=data; return data;\n",
    "  }}\n",
    "\n",
    "  function varShapes(vs, yTop) {{\n",
    "    const VARIANT_COLOR = \"#ff0000\", y_backbone = 0.5;\n",
    "    const shapes = [], traces = [];\n",
    "    vs.forEach(v => {{\n",
    "      const x = v.position;\n",
    "      shapes.push({{type:'line', x0:x, x1:x, y0:-0.5, y1:yTop, line:{{color:VARIANT_COLOR, width:2}} }});\n",
    "      traces.push({{x:[x], y:[y_backbone], mode:'markers', marker:{{symbol:'diamond', size:12, color:VARIANT_COLOR, line:{{color:'white', width:1}}}}, hoverinfo:'text', hovertext:`Variant ${{v.display}}` }});\n",
    "    }});\n",
    "    return {{shapes, traces}};\n",
    "  }}\n",
    "\n",
    "  let currentVariants = [];\n",
    "  async function apply(p) {{\n",
    "    const state = (await loadP(p))['noSingles'];\n",
    "    const extra = varShapes(currentVariants, state.yr[1]);\n",
    "    Plotly.react(gd, [...state.data, ...extra.traces], {{\n",
    "      ...gd.layout, title: {{text: state.title}},\n",
    "      shapes: [...state.shapes, ...extra.shapes], annotations: state.annotations,\n",
    "      xaxis: {{...gd.layout.xaxis, range: state.xr, title: {{text:'Amino acid position'}}, showgrid:false, zeroline:false}},\n",
    "      yaxis: {{...gd.layout.yaxis, range: state.yr, tickvals: state.tv, ticktext: state.tt, showgrid:false}}\n",
    "    }});\n",
    "  }}\n",
    "\n",
    "  sel.addEventListener('change', ()=>apply(sel.value));\n",
    "  sel.value = PROTEINS[0]; apply(sel.value);\n",
    "}}\n",
    "document.readyState === 'loading' ? document.addEventListener('DOMContentLoaded', initViewer) : initViewer();\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "html_out = html_core.replace(\"<body>\", \"<body>\\n\" + controls_html)\n",
    "with open(OUT_HTML, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_out)\n",
    "\n",
    "print(f\"‚úÖ Wrote viewer: {OUT_HTML}\")\n",
    "print(f\"Proteins written: {len(proteins_all)}\")\n",
    "print(f\"JSON location: {DATA_DIR} (bundle_by_letter={BUNDLE_BY_LETTER}, alpha_subfolders={ALPHA_SUBFOLDERS})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77c807-24ee-49ed-85ee-1581dc0b9b13",
   "metadata": {},
   "source": [
    "## Quick Lists: Proteins with MORFs / NLSs-NESs / SLiMs\n",
    "\n",
    "Exports a CSV and JSON summary to help pick test proteins quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b8366f-7f20-451f-a095-b3246f29e9df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Proteins with requested track features ===\n",
      "\n",
      "[MORFs] proteins: 72\n",
      "Top examples (protein: count):\n",
      "  - AF9: 2\n",
      "  - SNP29: 2\n",
      "  - P73: 2\n",
      "  - VIME: 2\n",
      "  - RLA2: 2\n",
      "  - GEMI: 2\n",
      "  - H4: 2\n",
      "  - P63: 2\n",
      "  - P53: 2\n",
      "  - OPTN: 1\n",
      "\n",
      "[NLSs/NESs] proteins: 5160\n",
      "Top examples (protein: count):\n",
      "  - TITIN: 301\n",
      "  - SRRM2: 106\n",
      "  - DYST: 98\n",
      "  - SYNE1: 90\n",
      "  - ASH1L: 84\n",
      "  - TTF1: 84\n",
      "  - ATRX: 83\n",
      "  - SYNE2: 77\n",
      "  - ASPM: 75\n",
      "  - CHD6: 75\n",
      "\n",
      "[SLiMs] proteins: 1093\n",
      "Top examples (protein: count):\n",
      "  - EP15R: 21\n",
      "  - THYG: 17\n",
      "  - EPS15: 15\n",
      "  - P53: 14\n",
      "  - NRIP1: 10\n",
      "  - CASR: 9\n",
      "  - JUN: 9\n",
      "  - PML: 9\n",
      "  - NFAC1: 9\n",
      "  - IL6RB: 8\n",
      "\n",
      "üìÑ Wrote details to: feature_proteins_MORFs_NLSs_SLIMs.csv\n",
      "üß≠ Wrote summary index to: feature_protein_index.json\n",
      "\n",
      "Quick pick-lists (first 10 each):\n",
      "  MORFs: ['AF9', 'SNP29', 'P73', 'VIME', 'RLA2', 'GEMI', 'H4', 'P63', 'P53', 'OPTN']\n",
      "  NLSs/NESs: ['TITIN', 'SRRM2', 'DYST', 'SYNE1', 'ASH1L', 'TTF1', 'ATRX', 'SYNE2', 'ASPM', 'CHD6']\n",
      "  SLiMs: ['EP15R', 'THYG', 'EPS15', 'P53', 'NRIP1', 'CASR', 'JUN', 'PML', 'NFAC1', 'IL6RB']\n"
     ]
    }
   ],
   "source": [
    "# --- Find proteins with MORFs, NLSs/NESs, and SLiMs features ---\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "PICKLE_OUT = \"parsed_features.pkl\"\n",
    "OUT_CSV    = \"feature_proteins_MORFs_NLSs_SLIMs.csv\"\n",
    "OUT_JSON   = \"feature_protein_index.json\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_pickle(PICKLE_OUT).copy()\n",
    "\n",
    "# Normalize Source_Column to reduce drift / synonyms\n",
    "norm_map = {\n",
    "    # LCS handled elsewhere; here we care about SLiMs / NLSs / MORFs synonyms\n",
    "    \"SLIM\": \"SLiMs\", \"SLIMs\": \"SLiMs\", \"Slims\": \"SLiMs\", \"SLiM\": \"SLiMs\",\n",
    "    \"NLS\": \"NLSs/NESs\", \"NES\": \"NLSs/NESs\", \"NLS/NES\": \"NLSs/NESs\",\n",
    "    \"NLSs\": \"NLSs/NESs\", \"NESs\": \"NLSs/NESs\",\n",
    "    \"Nuclear localization signal\": \"NLSs/NESs\",\n",
    "    \"Nuclear export signal\": \"NLSs/NESs\",\n",
    "    \"MoRF\": \"MORFs\", \"MoRFs\": \"MORFs\", \"MORF\": \"MORFs\"\n",
    "}\n",
    "df[\"Source_Column\"] = (\n",
    "    df[\"Source_Column\"].astype(str).str.strip()\n",
    "    .replace(norm_map)\n",
    ")\n",
    "\n",
    "target_tracks = [\"MORFs\", \"NLSs/NESs\", \"SLiMs\"]\n",
    "\n",
    "# Ensure numeric positions (useful if you want to filter/sort later)\n",
    "for col in (\"Start\", \"End\"):\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Subset to only requested tracks\n",
    "sub = df[df[\"Source_Column\"].isin(target_tracks)].copy()\n",
    "\n",
    "# Safety: keep useful columns only (add/remove as needed)\n",
    "cols = [c for c in [\"Protein\", \"Source_Column\", \"Feature_Type\", \"Start\", \"End\", \"seq_len\", \"Source\"] if c in sub.columns]\n",
    "sub = sub[cols].sort_values([\"Source_Column\", \"Protein\", \"Start\", \"End\"], na_position=\"last\")\n",
    "\n",
    "# Build summaries\n",
    "summary = {}\n",
    "for track in target_tracks:\n",
    "    dtrack = sub[sub[\"Source_Column\"] == track]\n",
    "    counts = dtrack[\"Protein\"].value_counts()\n",
    "    summary[track] = {\n",
    "        \"num_proteins_with_features\": int(counts.size),\n",
    "        \"top_proteins_by_feature_count\": counts.head(25).to_dict(),  # top-25 for quick picking\n",
    "    }\n",
    "\n",
    "# Write outputs for inspection\n",
    "sub.to_csv(OUT_CSV, index=False)\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Pretty print a quick console summary\n",
    "print(\"\\n=== Proteins with requested track features ===\")\n",
    "for track in target_tracks:\n",
    "    print(f\"\\n[{track}] proteins: {summary[track]['num_proteins_with_features']}\")\n",
    "    if summary[track][\"top_proteins_by_feature_count\"]:\n",
    "        print(\"Top examples (protein: count):\")\n",
    "        for p, n in list(summary[track][\"top_proteins_by_feature_count\"].items())[:10]:\n",
    "            print(f\"  - {p}: {n}\")\n",
    "    else:\n",
    "        print(\"  (No proteins found for this track.)\")\n",
    "\n",
    "print(f\"\\nüìÑ Wrote details to: {OUT_CSV}\")\n",
    "print(f\"üß≠ Wrote summary index to: {OUT_JSON}\")\n",
    "\n",
    "# Optional: quick ‚Äúpick lists‚Äù you can copy/paste into your viewer\n",
    "pick_lists = {\n",
    "    track: list(summary[track][\"top_proteins_by_feature_count\"].keys())[:10]\n",
    "    for track in target_tracks\n",
    "}\n",
    "print(\"\\nQuick pick-lists (first 10 each):\")\n",
    "for track, plist in pick_lists.items():\n",
    "    print(f\"  {track}: {plist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a1b1a-e262-4606-b048-b1fe91821704",
   "metadata": {},
   "source": [
    "## Reproducibility Notes\n",
    "\n",
    "- All outputs are deterministic given the same Excel input.\n",
    "- For large repositories: place the full `protein_data/` behind Git LFS or keep the demo subset.\n",
    "- The viewer HTML is in `docs/` so GitHub Pages can serve it automatically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
